{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e444039-68c6-4da3-9c43-4c3b68fc464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b6b894-804f-49fe-b7a7-a7e121aa6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D, MaxPooling2D, Flatten, Input\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c045041-e6c5-4b90-8c13-6a61ffd70481",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4dd09c-00c6-4dfa-845f-5059f15a5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Input(shape=(224,224,3)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116f88f2-b389-4958-b4cb-53f7d94322cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation='relu'))\n",
    "cnn.add(Dense(32,activation='relu'))\n",
    "cnn.add(Dense(16,activation='relu'))\n",
    "cnn.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a64291-7220-4a41-b878-3404519b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d215cc-18e4-4a89-b8c2-35c524c300bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c20467-2312-4b9e-bd52-0f4d3b5bd6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25098 images belonging to 2 classes.\n",
      "Found 6034 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python1\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m724/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m42s\u001b[0m 696ms/step - accuracy: 0.5181 - loss: 0.6914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python1\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.5201 - loss: 0.6910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python1\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 769ms/step - accuracy: 0.5202 - loss: 0.6910 - val_accuracy: 0.6313 - val_loss: 0.6465\n",
      "Epoch 2/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 588ms/step - accuracy: 0.6386 - loss: 0.6408 - val_accuracy: 0.6787 - val_loss: 0.6029\n",
      "Epoch 3/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 590ms/step - accuracy: 0.6909 - loss: 0.5910 - val_accuracy: 0.7436 - val_loss: 0.5226\n",
      "Epoch 4/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 589ms/step - accuracy: 0.7291 - loss: 0.5414 - val_accuracy: 0.7730 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 590ms/step - accuracy: 0.7593 - loss: 0.4990 - val_accuracy: 0.8028 - val_loss: 0.4329\n",
      "Epoch 6/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 588ms/step - accuracy: 0.7795 - loss: 0.4661 - val_accuracy: 0.8020 - val_loss: 0.4319\n",
      "Epoch 7/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 585ms/step - accuracy: 0.7889 - loss: 0.4534 - val_accuracy: 0.8190 - val_loss: 0.4052\n",
      "Epoch 8/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 589ms/step - accuracy: 0.7961 - loss: 0.4397 - val_accuracy: 0.8222 - val_loss: 0.4041\n",
      "Epoch 9/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 589ms/step - accuracy: 0.8014 - loss: 0.4325 - val_accuracy: 0.8069 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 587ms/step - accuracy: 0.8022 - loss: 0.4290 - val_accuracy: 0.8199 - val_loss: 0.4124\n",
      "Epoch 11/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 584ms/step - accuracy: 0.8094 - loss: 0.4158 - val_accuracy: 0.8404 - val_loss: 0.3650\n",
      "Epoch 12/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 583ms/step - accuracy: 0.8195 - loss: 0.4030 - val_accuracy: 0.8543 - val_loss: 0.3502\n",
      "Epoch 13/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 581ms/step - accuracy: 0.8249 - loss: 0.3916 - val_accuracy: 0.8518 - val_loss: 0.3414\n",
      "Epoch 14/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 583ms/step - accuracy: 0.8294 - loss: 0.3819 - val_accuracy: 0.8407 - val_loss: 0.3519\n",
      "Epoch 15/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 582ms/step - accuracy: 0.8280 - loss: 0.3808 - val_accuracy: 0.8465 - val_loss: 0.3430\n",
      "Epoch 16/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 588ms/step - accuracy: 0.8365 - loss: 0.3719 - val_accuracy: 0.8348 - val_loss: 0.3615\n",
      "Epoch 17/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 590ms/step - accuracy: 0.8354 - loss: 0.3678 - val_accuracy: 0.8682 - val_loss: 0.3133\n",
      "Epoch 18/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 599ms/step - accuracy: 0.8402 - loss: 0.3605 - val_accuracy: 0.8606 - val_loss: 0.3269\n",
      "Epoch 19/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 592ms/step - accuracy: 0.8393 - loss: 0.3599 - val_accuracy: 0.8673 - val_loss: 0.3105\n",
      "Epoch 20/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 591ms/step - accuracy: 0.8482 - loss: 0.3463 - val_accuracy: 0.8472 - val_loss: 0.3422\n",
      "Epoch 21/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 589ms/step - accuracy: 0.8517 - loss: 0.3394 - val_accuracy: 0.8734 - val_loss: 0.3011\n",
      "Epoch 22/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 595ms/step - accuracy: 0.8442 - loss: 0.3563 - val_accuracy: 0.8765 - val_loss: 0.2954\n",
      "Epoch 23/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 631ms/step - accuracy: 0.8494 - loss: 0.3417 - val_accuracy: 0.8722 - val_loss: 0.2939\n",
      "Epoch 24/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 637ms/step - accuracy: 0.8572 - loss: 0.3288 - val_accuracy: 0.8820 - val_loss: 0.2774\n",
      "Epoch 25/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 595ms/step - accuracy: 0.8565 - loss: 0.3337 - val_accuracy: 0.8784 - val_loss: 0.2932\n",
      "Epoch 26/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 651ms/step - accuracy: 0.8540 - loss: 0.3297 - val_accuracy: 0.8742 - val_loss: 0.2906\n",
      "Epoch 27/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 673ms/step - accuracy: 0.8631 - loss: 0.3169 - val_accuracy: 0.8870 - val_loss: 0.2747\n",
      "Epoch 28/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 652ms/step - accuracy: 0.8620 - loss: 0.3152 - val_accuracy: 0.8752 - val_loss: 0.2911\n",
      "Epoch 29/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 650ms/step - accuracy: 0.8658 - loss: 0.3109 - val_accuracy: 0.8815 - val_loss: 0.2750\n",
      "Epoch 30/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 659ms/step - accuracy: 0.8681 - loss: 0.3012 - val_accuracy: 0.8825 - val_loss: 0.2745\n",
      "Epoch 31/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 670ms/step - accuracy: 0.8676 - loss: 0.3051 - val_accuracy: 0.8772 - val_loss: 0.2768\n",
      "Epoch 32/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 669ms/step - accuracy: 0.8644 - loss: 0.3065 - val_accuracy: 0.8813 - val_loss: 0.2725\n",
      "Epoch 33/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 658ms/step - accuracy: 0.8728 - loss: 0.2972 - val_accuracy: 0.8929 - val_loss: 0.2532\n",
      "Epoch 34/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 671ms/step - accuracy: 0.8704 - loss: 0.3059 - val_accuracy: 0.8828 - val_loss: 0.2663\n",
      "Epoch 35/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 652ms/step - accuracy: 0.8750 - loss: 0.2987 - val_accuracy: 0.8805 - val_loss: 0.2743\n",
      "Epoch 36/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 601ms/step - accuracy: 0.8752 - loss: 0.2877 - val_accuracy: 0.8959 - val_loss: 0.2473\n",
      "Epoch 37/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 606ms/step - accuracy: 0.8739 - loss: 0.2949 - val_accuracy: 0.8798 - val_loss: 0.2678\n",
      "Epoch 38/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 610ms/step - accuracy: 0.8773 - loss: 0.2863 - val_accuracy: 0.8987 - val_loss: 0.2417\n",
      "Epoch 39/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 594ms/step - accuracy: 0.8791 - loss: 0.2844 - val_accuracy: 0.8949 - val_loss: 0.2425\n",
      "Epoch 40/40\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 598ms/step - accuracy: 0.8801 - loss: 0.2822 - val_accuracy: 0.8863 - val_loss: 0.2656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23edb9ca8a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\ML Course\\Cat_dog_training_data\",\n",
    "        target_size=(224,224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\ML Course\\cat_dog_testing_data\",\n",
    "        target_size=(224,224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=785,\n",
    "        epochs=40,\n",
    "        validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d2bcaf-3517-4f0c-b39a-cab0e12fcc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "print(len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f4308d-4402-4937-a12a-8f4f4ad2891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "647fd6eb-a544-48dc-8d78-0943209c849c",
   "metadata": {},
   "source": [
    "# Save the model, target size=(150,150)\n",
    "from keras.saving import save_model\n",
    "save_model(cnn, \"cat_dog_model.keras\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83044d10-9084-4a53-beb3-dc1b1f555853",
   "metadata": {},
   "source": [
    "# Save the model, target size=(224,224)\n",
    "from keras.saving import save_model\n",
    "save_model(cnn, \"cat_dog_cnn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0512425b-c6f3-4242-9bb2-8a02afb25357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model, target size=(150,150)\n",
    "from keras.models import load_model\n",
    "model = load_model(\"cat_dog_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad73de33-9240-43a1-a023-a845bffb82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model, target size=(224,224)\n",
    "from keras.models import load_model\n",
    "cnn_model = load_model(\"cat_dog_cnn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f88f88e1-d470-487d-8910-a07737b0a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c0ebf26-0b46-481a-9cb3-2efd4c4e6248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[[1.]] 1.0\n",
      "From 224 traget size: Dog\n"
     ]
    }
   ],
   "source": [
    "image1= image.load_img(r\"C:\\ML Course\\testing_image_6.jpg\",target_size=(224,224))\n",
    "img = image.img_to_array(image1)\n",
    "import numpy as np\n",
    "imgg = np.expand_dims(img,axis=0)\n",
    "\n",
    "p1 = cnn_model.predict(imgg)\n",
    "print(p, p[0][0])\n",
    "if p[0][0] < 0.5:\n",
    "    print(\"From 224 traget size: Cat\")\n",
    "else:\n",
    "    print(\"From 224 traget size: Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b0b2a4f-b5f3-41f3-894c-15b802cfb543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "[[1.]] 1.0\n",
      "From 150 traget size: Dog\n"
     ]
    }
   ],
   "source": [
    "image1= image.load_img(r\"C:\\ML Course\\testing_image_6.jpg\",target_size=(150,150))\n",
    "img = image.img_to_array(image1)\n",
    "import numpy as np\n",
    "imgg = np.expand_dims(img,axis=0)\n",
    "\n",
    "p2 = model.predict(imgg)\n",
    "print(p2, p2[0][0])\n",
    "if p2[0][0] < 0.5:\n",
    "    print(\"From 150 traget size: Cat\")\n",
    "else:\n",
    "    print(\"From 150 traget size: Dog\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20219367-e9f3-407d-9488-8e6eef3af895",
   "metadata": {},
   "source": [
    "if p[0][0] < 0.5:\n",
    "    print(\"cat\")\n",
    "else:\n",
    "    print(\"dog\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7c34d6f-dc3c-4019-9353-1b75a465677c",
   "metadata": {},
   "source": [
    "# cnn.save(\"cat_dog_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36032048-4fce-45c6-a493-047b93ab2ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
